using ModelDeploy;
using ModelDeploy.audio.asr;
using ModelDeploy.audio.tts;
using ModelDeploy.types_internal_c;
using ModelDeploy.utils;
using ModelDeploy.vision.detection;
using ModelDeploy.vision.face;
using ModelDeploy.vision.ocr;

namespace TestModelDeploy;

class Program
{
    static void TestSenseVoice()
    {
        MDSenseVoiceParameters parameters = new MDSenseVoiceParameters
        {
            model_path =
                "E:/CLionProjects/onnxruntime_test/tests/test_models/sense-voice-zh-en-ja-ko-yue/model.onnx",
            use_itn = 1,
            language = "auto",
            tokens_path = "E:/CLionProjects/onnxruntime_test/tests/test_models/sense-voice-zh-en-ja-ko-yue/tokens.txt",
            num_threads = 1,
            debug = 0,
        };

        SenseVoice senseVoice = new SenseVoice(parameters);
        ASRResult result = senseVoice.Predict("D:/funasr-runtime-resources/vad_example.wav");
        Console.WriteLine(result.Message);
    }

    static void TestKokoro()
    {
        MDKokoroParameters parameters = new MDKokoroParameters
        {
            model_path = "E:/CLionProjects/onnxruntime_test/tests/test_models/kokoro-multi-lang-v1_0/model.onnx",
            voices_path = "E:/CLionProjects/onnxruntime_test/tests/test_models/kokoro-multi-lang-v1_0/voices.bin",
            tokens_path = "E:/CLionProjects/onnxruntime_test/tests/test_models/kokoro-multi-lang-v1_0/tokens.txt",
            data_dir = "E:/CLionProjects/onnxruntime_test/tests/test_models/kokoro-multi-lang-v1_0/espeak-ng-data",
            dict_dir = "E:/CLionProjects/onnxruntime_test/tests/test_models/kokoro-multi-lang-v1_0/dict",
            lexicon = "E:/CLionProjects/onnxruntime_test/tests/test_models/kokoro-multi-lang-v1_0/lexicon-us-en.txt," +
                      "E:/CLionProjects/onnxruntime_test/tests/test_models/kokoro-multi-lang-v1_0/lexicon-zh.txt",
            num_threads = 1,
            debug = 0
        };
        Kokoro kokoro = new Kokoro(parameters);
        string text = "中英文语音合成测试。This is generated by next generation Kaldi using Kokoro without Misaki. 你觉得中英文说的如何呢？";
        // 音色
        int sid = 48;
        // 速度
        float speed = 1;
        string wavPath = "result.wav";
        kokoro.Predict(text, sid, speed, wavPath);
    }

    static void TestDetection()
    {
        Image image = Image.Read("E:/CLionProjects/onnxruntime_test/tests/test_images/test_detection.png");
        YOLOv8 yolov8 = new YOLOv8("E:/CLionProjects/onnxruntime_test/tests/test_models/best.onnx");
        yolov8.SetInputSize(1440, 1440);
        List<DetectionResult> detectionResults = yolov8.Predict(image);
        yolov8.DrawDetectionResult(image, detectionResults, "E:/CLionProjects/onnxruntime_test/tests/msyh.ttc", 20,
            0.5);
        image.Show();
        foreach (var detectionResult in detectionResults)
        {
            Console.WriteLine(detectionResult.Box);
        }
    }

    static void TestImage()
    {
        Image image = Image.Read("E:/CLionProjects/onnxruntime_test/tests/test_images/test_detection.png");
        Rect rect = new Rect { X = 0, Y = 0, Width = 100, Height = 100 };
        Rect rect1 = new Rect { X = 200, Y = 200, Width = 100, Height = 100 };
        Rect rect2 = new Rect { X = 100, Y = 100, Width = 500, Height = 500 };
        Color color = new Color { R = 255, G = 0, B = 0 };
        Draw.DrawRect(image, rect, color, 0.5);
        Draw.DrawText(image, rect1, "Hello World", "E:/CLionProjects/onnxruntime_test/tests/msyh.ttc", 20, color, 0.5);
        var cloneImage = image.Clone();
        var cropImage = cloneImage.Crop(rect2);
        cropImage.Show();
        cropImage.Save("2.jpg");
    }

    static void TestOCR()
    {
        MDOCRModelParameters parameters = new MDOCRModelParameters
        {
            // 最后注意必须加斜杠
            model_dir = "E:/CLionProjects/onnxruntime_test/tests/test_models/ocr/",
            dict_path = "E:/CLionProjects/onnxruntime_test/tests/key.txt",
            thread_num = 8,
            format = MDModelFormat.ONNX,
            max_side_len = 1920,
            det_db_thresh = 0.3,
            det_db_box_thresh = 0.6,
            det_db_unclip_ratio = 1.5,
            det_db_score_mode = "slow",
            use_dilation = 0,
            rec_batch_size = 8,
        };
        Image image = Image.Read("E:/CLionProjects/onnxruntime_test/tests/test_images/test_ocr1.png");
        PPOCRv4 ppocrv4 = new PPOCRv4(parameters);
        List<OCRResult> results = ppocrv4.Predict(image);
        ppocrv4.DrawOcrResult(image, results, "E:/CLionProjects/onnxruntime_test/tests/msyh.ttc", new Color
        {
            R = 0,
            G = 0,
            B = 255
        }, 15, 0.3, 1);
        image.Show();
        foreach (var result in results)
        {
            Console.WriteLine(result.Text);
        }
    }

    static void TestFace()
    {
        Image image0 = Image.Read("E:/CLionProjects/ModelDeploy/tests/test_images/test_face.jpg");
        Image image1 = Image.Read("E:/CLionProjects/ModelDeploy/tests/test_images/test_face1.jpg");
        Image image2 = Image.Read("E:/CLionProjects/ModelDeploy/tests/test_images/test_face2.jpg");
        Image image3 = Image.Read("E:/CLionProjects/ModelDeploy/tests/test_images/test_face3.jpg");

        SeetaFace seetaFace =
            new SeetaFace("E:/CLionProjects/ModelDeploy/tests/models/seetaface", FaceConstants.MD_MASK, 8);
        var detectionResults = seetaFace.FaceDetect(image3);
        Console.WriteLine($"Detection {detectionResults.Count} faces in image3");

        var points = seetaFace.FaceLandmark(image3, detectionResults[0].Box);

        var feature0 = seetaFace.FaceFeatureExtract(image0);
        var feature1 = seetaFace.FaceFeatureExtract(image1);
        var feature2 = seetaFace.FaceFeatureExtract(image2);
        var feature3 = seetaFace.FaceFeatureExtract(image3, points);

        var similarity0 = seetaFace.FaceFeatureCompare(feature0, feature1);
        Console.WriteLine($"similarity between image0 and image1 is: {similarity0}");
        var similarity1 = seetaFace.FaceFeatureCompare(feature0, feature2);
        Console.WriteLine($"similarity between image0 and image2 is: {similarity1}");

        var ret = seetaFace.FaceAntiSpoofing(image0);
        Console.WriteLine($"AntiSpoofing result: {ret}");

        var age = seetaFace.FaceAgePredict(image0);
        Console.WriteLine($"Age predict result: {age}");
        var gender = seetaFace.FaceGenderPredict(image0);
        Console.WriteLine($"Gender predict result: {gender}");

        var quality0 = seetaFace.FaceQualityEvaluate(image0, FaceQualityEvaluateType.Brightness);
        Console.WriteLine($"Brightness quality: {quality0}");
        var quality1 = seetaFace.FaceQualityEvaluate(image0, FaceQualityEvaluateType.Clarity);
        Console.WriteLine($"Clarity quality: {quality1}");
        var quality2 = seetaFace.FaceQualityEvaluate(image0, FaceQualityEvaluateType.Integrity);
        Console.WriteLine($"Integrity quality: {quality2}");
        var quality3 = seetaFace.FaceQualityEvaluate(image0, FaceQualityEvaluateType.Pose);
        Console.WriteLine($"Pose quality: {quality3}");
        var quality4 = seetaFace.FaceQualityEvaluate(image0, FaceQualityEvaluateType.ClarityEx);
        Console.WriteLine($"ClarityEx quality: {quality4}");
        var quality5 = seetaFace.FaceQualityEvaluate(image0, FaceQualityEvaluateType.Resolution);
        Console.WriteLine($"Resolution quality: {quality5}");
        var quality6 = seetaFace.FaceQualityEvaluate(image0, FaceQualityEvaluateType.NoMask);
        Console.WriteLine($"NoMask quality: {quality6}");

        var eyeState0 = seetaFace.FaceEyeStatePredict(image0);
        Console.WriteLine($"image0: {eyeState0}");
        var eyeState1 = seetaFace.FaceEyeStatePredict(image2);
        Console.WriteLine($"image2: {eyeState1}");
    }


    static void TestOcrRecognition()
    {
        OCRRecognition ocrRecognition =
            new OCRRecognition("E:/CLionProjects/onnxruntime_test/tests/test_models/ocr/rec_infer.onnx",
                "E:/CLionProjects/onnxruntime_test/tests/key.txt");
        Image image = Image.Read("E:/CLionProjects/onnxruntime_test/tests/test_images/test_ocr_recognition.png");
        var result = ocrRecognition.Predict(image);
        Console.WriteLine(result);
    }

    static void TestOcrRecognitionBatch()
    {
        OCRRecognition ocrRecognition =
            new OCRRecognition("E:/CLionProjects/onnxruntime_test/tests/test_models/ocr/rec_infer.onnx",
                "E:/CLionProjects/onnxruntime_test/tests/key.txt");
        Image image = Image.Read("E:/CLionProjects/onnxruntime_test/tests/test_images/ocr_check_report.png");

        // image
        // |------------------|-|- 
        // |                  | |   
        // |                  | image_height
        // |                  | |
        // |------------------|-|- 
        // |---image_width ---|

        //bounding box
        // |-------------|-|- 
        // |             | |   
        // |      *      | h
        // |  (x_c,y_c)  | |
        // |-------------|-|- 
        // |----- w -----|

        // test case1: image: ocr_check_report.png(位置标注为归一化后的矩形框，将矩形框[xc,yc,w,h]转化为[x1,y1,x2,y2,x3,y3,x4,y4])
        // image_width:2446 
        // image_height:3462 
        // x_center1:0.3849 y_center1:0.0604 w1:0.3684 h1:0.0179
        // x_center2:0.2817 y_center2:0.1776 w2:0.2069 h2:0.0133

        // test case2: image: test_ocr1.png（直接给出文字所在的位置由[x1,y1,x2,y2,x3,y3,x4,y4]直接给出的四个角点的多边形）
        // x1:17  y1:16  x2:288,  y2:18 x3:288,  y3:45  x4:17,  y4:43
        // x1:20  y1:54  x2:65,   y2:56 x3:61,   y3:74  x4:19,  y4:72


        var x_center1 = Convert.ToInt32(0.3849 * 2466);
        var y_center1 = Convert.ToInt32(0.0604 * 3462);
        var w1 = Convert.ToInt32(0.3684 * 2466);
        var h1 = Convert.ToInt32(0.0179 * 3462);

        var x_center2 = Convert.ToInt32(0.2817 * 2466);
        var y_center2 = Convert.ToInt32(0.1776 * 3462);
        var w2 = Convert.ToInt32(0.2069 * 2466);
        var h2 = Convert.ToInt32(0.0133 * 3462);

        var p1 = new Point { X = x_center1 - w1 / 2, Y = y_center1 - h1 / 2 };
        var p2 = new Point { X = x_center1 + w1 / 2, Y = y_center1 - h1 / 2 };
        var p3 = new Point { X = x_center1 + w1 / 2, Y = y_center1 + h1 / 2 };
        var p4 = new Point { X = x_center1 - w1 / 2, Y = y_center1 + h1 / 2 };

        var p5 = new Point { X = x_center2 - w2 / 2, Y = y_center2 - h2 / 2 };
        var p6 = new Point { X = x_center2 + w2 / 2, Y = y_center2 - h2 / 2 };
        var p7 = new Point { X = x_center2 + w2 / 2, Y = y_center2 + h2 / 2 };
        var p8 = new Point { X = x_center2 - w2 / 2, Y = y_center2 + h2 / 2 };

        List<Point> points1 = [p1, p2, p3, p4];
        List<Point> points2 = [p5, p6, p7, p8];
        List<Polygon> polygons = [Polygon.FromPointList(points1), Polygon.FromPointList(points2)];

        List<OCRResult> results = ocrRecognition.BatchPredict(image, polygons, 2);
        Draw.DrawPolygon(image, polygons[0], new Color { R = 255, G = 255, B = 0 }, 0.5);
        Draw.DrawPolygon(image, polygons[1], new Color { R = 255, G = 0, B = 0 }, 0.5);
        image.Show();

        foreach (var result in results)
        {
            Console.WriteLine(result);
        }
    }

    static void Main(string[] args)
    {
        // TestSenseVoice();
        // TestKokoro();
        // TestDetection();
        // TestImage();
        // TestOCR();
        // TestOcrRecognition();
        TestOcrRecognitionBatch();
        // TestFace();
        // 测试GC
        GC.Collect();
        GC.WaitForPendingFinalizers();
    }
}